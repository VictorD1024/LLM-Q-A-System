{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","mount_file_id":"1sUskaHoE7xAU0P1l9nCnonuhMYTrw5fr","authorship_tag":"ABX9TyOgORxhBSGgJQ/5dulXu64f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i7V5eJEhFVLE","executionInfo":{"status":"ok","timestamp":1731565234449,"user_tz":-660,"elapsed":47034,"user":{"displayName":"Victor D","userId":"12661807456237465201"}},"outputId":"54c49776-27a8-455e-e4b4-68987de76b56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Model and tokenizer loaded successfully!\n"]}],"source":["from google.colab import drive\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import torch\n","# Google Drive\n","drive.mount('/content/drive')\n","\n","\n","model_path = \"/content/drive/MyDrive/9900_LLM Q&A System/\"\n","\n","\n","model = GPT2LMHeadModel.from_pretrained(model_path)\n","tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n","tokenizer.pad_token = tokenizer.eos_token  # fill token\n","\n","# evaluate pattern\n","model.eval()\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model.to(device)\n","\n","print(\"Model and tokenizer loaded successfully!\")\n"]},{"cell_type":"code","source":["import torch\n","\n","def generate_answer(question, max_length=50):\n","    \"\"\"Generate concise responses based on input questions\"\"\"\n","    prompt = f\"Q: {question}\\nA:\"\n","\n","    # Tokenize the input and convert it to a tensor\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            **inputs,\n","            max_length=max_length,  # Limit the build length\n","            temperature=0.5,  # Reduce diversity\n","            top_k=30,  # Limit the scope of candidates\n","            top_p=0.8,  # Nuclear sampling, reducing redundancy\n","            no_repeat_ngram_size=2,  # Prevent the generation of duplicates n-gram\n","            eos_token_id=tokenizer.eos_token_id,\n","            early_stopping=True  # stop early build\n","        )\n","\n","\n","    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","    answer = answer.split(\"A:\", 1)[-1].strip()\n","    return answer\n","\n","\n","import re\n","\n","def clean_answer(answer):\n","\n","    cleaned_answer = re.sub(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', '', answer)\n","\n","    cleaned_answer = re.sub(r'\\s+', ' ', cleaned_answer).strip()\n","    return cleaned_answer\n"],"metadata":{"id":"_scMq8jRIfpS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import re\n","\n","def generate_answer(question, max_length=50):\n","    \"\"\"Generate concise responses based on input questions\"\"\"\n","    prompt = f\"Q: {question}\\nA:\"\n","\n","    # Tokenize the input and convert it to a tensor\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","\n","    try:\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                **inputs,\n","                max_length=max_length,  # Limit the build length\n","                temperature=0.5,  # Reduce diversity\n","                top_k=30,  # Limit the scope of candidates\n","                top_p=0.8,  # Nuclear sampling, reducing redundancy\n","                no_repeat_ngram_size=2,  # Prevent the generation of duplicates n-gram\n","                eos_token_id=tokenizer.eos_token_id,\n","                early_stopping=True  # stop early build\n","            )\n","\n","        answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        answer = answer.split(\"A:\", 1)[-1].strip()  # Remove prompt prefix\n","    except Exception as e:\n","        answer = f\"An error occurred: {str(e)}\"\n","\n","    return answer\n","\n","def clean_answer(answer):\n","    \"\"\"Clean up the generated answer by removing unwanted patterns\"\"\"\n","    # Remove datetime patterns (e.g., \"2024-11-07 16:11:45\")\n","    cleaned_answer = re.sub(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', '', answer)\n","\n","    # Remove extra spaces and trim the answer\n","    cleaned_answer = re.sub(r'\\s+', ' ', cleaned_answer).strip()\n","\n","    # Optionally, remove other unwanted characters or patterns if necessary\n","    return cleaned_answer\n"],"metadata":{"id":"OS2rL2QMNIaH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test question\n","questions = [\n","    \"How IoT improves the efficiency of building management systems\",\n","    \"What are the different types of sensors in the Internet of Things?\",\n","    \"What is HVAC in the context of a BMS?\",\n","    \"What are the advantages of smart building technologies?\"\n","]\n","\n","# Traverse the question to generate an answer\n","for question in questions:\n","    answer = generate_answer(question)\n","    print(f\"Question: {question}\\nAnswer: {answer}\\n\")\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UrAs5rjpIhv6","executionInfo":{"status":"ok","timestamp":1731565265834,"user_tz":-660,"elapsed":2915,"user":{"displayName":"Victor D","userId":"12661807456237465201"}},"outputId":"5252469e-1e70-47e4-ec00-6f547a86c9c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `30` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Question: How IoT improves the efficiency of building management systems\n","Answer: A BMS optimizes the energy efficiency by managing energy consumption by using IoT devices to optimize energy use. The system can optimize the heating temperature setpoint by adjusting the fan speed in\n","\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What are the different types of sensors in the Internet of Things?\n","Answer: Sensor for IoT is a relatively simple way to connect and communicate. It can connect IoT devices via the internet via a network. The Internet is about connecting things,\n","\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is HVAC in the context of a BMS?\n","Answer: Hvac systems are used in a variety of applications, including IoT devices, sensors, and equipment. These applications can be integrated with a wider range of systems\n","\n","Question: What are the advantages of smart building technologies?\n","Answer: A BMS can be integrated with existing systems to improve energy efficiency. It can also be used to optimize energy consumption by providing a wider range of communication protocols.\n","\n"]}]},{"cell_type":"code","source":["!pip install faiss-cpu # Install faiss for CPU usage"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqGHjvGzJTwk","executionInfo":{"status":"ok","timestamp":1731495027074,"user_tz":-660,"elapsed":4415,"user":{"displayName":"Victor D","userId":"12661807456237465201"}},"outputId":"dd59e7e3-44a8-4e8c-e5f9-0a39592d822c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting faiss-cpu\n","  Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n","Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.9.0\n"]}]},{"cell_type":"code","source":["# 准备验证集输入数据\n","test_inputs = [\n","    \"Example input text 1\",\n","    \"Example input text 2\",\n","    # 添加更多输入\n","]\n","\n","# 生成预测\n","predictions = []\n","for input_text in test_inputs:\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","    output = model.generate(input_ids, max_length=50)\n","    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n","    predictions.append(decoded_output)"],"metadata":{"id":"67k2hSfHbrKu"},"execution_count":null,"outputs":[]}]}